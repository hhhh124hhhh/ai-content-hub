import { execSync } from 'child_process';

export interface ScrapeResult {
  success: boolean;
  prompts: any[];
  error?: string;
}

export class ScraperService {
  /**
   * ä» Twitter/X æŠ“å–æç¤ºè¯ï¼ˆä½¿ç”¨ bird skillï¼‰
   */
  static async scrapeTwitter(
    query: string,
    count: number = 20
  ): Promise<ScrapeResult> {
    try {
      console.log(`ğŸ” Scraping Twitter for: ${query}`);

      // å°è¯•ä½¿ç”¨ bird CLI
      let results: any[];
      try {
        const birdOutput = execSync(`bird tweets "${query}" --limit ${count} --json`, {
          encoding: 'utf-8'
        });
        
        results = JSON.parse(birdOutput);
      } catch (error) {
        console.error('âŒ Bird CLI error:', error);
        return {
          success: false,
          prompts: [],
          error: 'Bird CLI not configured or failed'
        };
      }

      if (!results || results.length === 0) {
        console.log('âš ï¸  No tweets found');
        return {
          success: false,
          prompts: [],
          error: 'No tweets found'
        };
      }

      console.log(`âœ… Found ${results.length} tweets`);

      // è½¬æ¢ä¸ºæç¤ºè¯æ ¼å¼
      const prompts = results.map((tweet: any) => ({
        title: tweet.text.substring(0, 100),
        description: tweet.text.substring(0, 200),
        content: tweet.text,
        type: this.detectType(tweet.text),
        category: this.detectCategory(tweet.text),
        tags: this.extractTags(tweet.text),
        models: this.detectModels(tweet.text),
        difficulty: this.detectDifficulty(tweet.text),
        useCases: this.extractUseCases(tweet.text),
        author: {
          username: tweet.username,
          followerCount: tweet.follower_count || 0,
          verified: tweet.verified || false,
          professional: (tweet.follower_count || 0) > 10000,
          expertise: this.detectExpertise(tweet.text)
        },
        publishedAt: new Date(tweet.date || tweet.created_at),
        scrapedAt: new Date(),
        metrics: {
          likes: tweet.favorite_count || 0,
          retweets: tweet.retweet_count || 0,
          replies: tweet.reply_count || 0,
          quotes: tweet.quote_count || 0,
          bookmarks: tweet.bookmark_count || 0,
          views: tweet.views || 0
        }
      }));

      console.log(`âœ… Converted ${prompts.length} tweets to prompts`);

      return {
        success: true,
        prompts
      };
    } catch (error) {
      console.error('âŒ Error scraping Twitter:', error);
      return {
        success: false,
        prompts: [],
        error: error.message
      };
    }
  }

  /**
   * æ£€æµ‹æç¤ºè¯ç±»å‹
   */
  static detectType(text: string): 'writing' | 'coding' | 'marketing' | 'design' | 'analysis' | 'other' {
    const keywords = {
      writing: ['å†™', 'æ–‡ç« ', 'åšå®¢', 'é‚®ä»¶', 'æ–‡æ¡ˆ', 'å†…å®¹', 'åˆ›ä½œ'],
      coding: ['ä»£ç ', 'ç¼–ç¨‹', 'å¼€å‘', 'åº”ç”¨', 'ç½‘ç«™', 'ç®—æ³•', 'è°ƒè¯•', 'ä¼˜åŒ–'],
      marketing: ['è¥é”€', 'å¹¿å‘Š', 'æ¨å¹¿', 'é”€å”®', 'è½¬åŒ–', 'å“ç‰Œ', 'å¸‚åœº'],
      design: ['è®¾è®¡', 'UI', 'UX', 'è§†è§‰', 'å›¾å½¢', 'å›¾ç‰‡', 'è‰²å½©', 'æ’ç‰ˆ'],
      analysis: ['åˆ†æ', 'æ•°æ®', 'ç»Ÿè®¡', 'æŠ¥å‘Š', 'æ´å¯Ÿ', 'é¢„æµ‹', 'æ¨¡å‹']
    };

    text = text.toLowerCase();

    for (const [type, typeKeywords] of Object.entries(keywords)) {
      if (typeKeywords.some(keyword => text.includes(keyword))) {
        return type as any;
      }
    }

    return 'other';
  }

  /**
   * æ£€æµ‹åˆ†ç±»
   */
  static detectCategory(text: string): string {
    const categories = {
      'ChatGPTå†™ä½œ': ['chatgpt', 'gpt', 'å†™ä½œ', 'æ–‡ç« ', 'åšå®¢'],
      'ç¼–ç¨‹å¼€å‘': ['ç¼–ç¨‹', 'å¼€å‘', 'ä»£ç ', 'åº”ç”¨', 'ç½‘ç«™'],
      'AIå·¥å…·': ['å·¥å…·', 'åº”ç”¨', 'å¹³å°', 'è½¯ä»¶'],
      'AIç ”ç©¶': ['ç ”ç©¶', 'è®ºæ–‡', 'æ¨¡å‹', 'ç®—æ³•'],
      'AIæ•™ç¨‹': ['æ•™ç¨‹', 'å­¦ä¹ ', 'å…¥é—¨', 'æŒ‡å—'],
      'AIæŠ€å·§': ['æŠ€å·§', 'æ–¹æ³•', 'æœ€ä½³å®è·µ']
    };

    text = text.toLowerCase();

    for (const [category, keywords] of Object.entries(categories)) {
      if (keywords.some(keyword => text.includes(keyword))) {
        return category;
      }
    }

    return 'é€šç”¨';
  }

  /**
   * æå–æ ‡ç­¾
   */
  static extractTags(text: string): string[] {
    const tags = [];
    const patterns = {
      hashtags: /#[\w]+/g,
      keywords: /(?:å†™ä½œ|ç¼–ç¨‹|è¥é”€|è®¾è®¡|åˆ†æ|æ•™ç¨‹|æŠ€å·§|å·¥å…·|åº”ç”¨|å¹³å°|è½¯ä»¶|ç®—æ³•|æ¨¡å‹|gpt|chatgpt|claude|ai|äººå·¥æ™ºèƒ½|æœºå™¨å­¦ä¹ |æ·±åº¦å­¦ä¹ )/gi,
      model: /(?:ChatGPT|Claude|Gemini|Midjourney|Stable Diffusion|DALL-E)/gi
    };

    // æå– hashtags
    const hashtags = text.match(patterns.hashtags);
    if (hashtags) {
      tags.push(...hashtags.map(tag => tag.replace('#', '').toLowerCase()));
    }

    // æå–å…³é”®è¯
    const keywords = text.match(patterns.keywords);
    if (keywords) {
      tags.push(...keywords.map(kw => kw.toLowerCase()));
    }

    // æå–æ¨¡å‹
    const model = text.match(patterns.model);
    if (model) {
      tags.push(model[0].toLowerCase());
    }

    // å»é‡
    return [...new Set(tags)].slice(0, 10);
  }

  /**
   * æ£€æµ‹æ¨¡å‹
   */
  static detectModels(text: string): string[] {
    const models = [];
    const patterns = {
      chatgpt: /ChatGPT|chatgpt|GPT-?/gi,
      claude: /Claude|claude|anthropic/gi,
      gemini: /Gemini|gemini|google/gi,
      midjourney: /Midjourney|midjourney|mj/gi,
      stableDiffusion: /Stable Diffusion|stable diffusion|sdxl/gi,
      dalle: /DALL-E|dalle|dall-e/gi
    };

    text = text.toLowerCase();

    for (const [model, pattern] of Object.entries(patterns)) {
      if (pattern.test(text)) {
        models.push(model);
      }
    }

    return [...new Set(models)].slice(0, 5);
  }

  /**
   * æ£€æµ‹éš¾åº¦
   */
  static detectDifficulty(text: string): 'beginner' | 'intermediate' | 'advanced' {
    const beginnerKeywords = ['å…¥é—¨', 'åŸºç¡€', 'æ–°æ‰‹', 'åˆçº§', 'å¼€å§‹'];
    const advancedKeywords = ['é«˜çº§', 'è¿›é˜¶', 'ç²¾é€š', 'ä¸“å®¶', 'æ·±åº¦'];

    text = text.toLowerCase();

    if (beginnerKeywords.some(kw => text.includes(kw))) {
      return 'beginner';
    }

    if (advancedKeywords.some(kw => text.includes(kw))) {
      return 'advanced';
    }

    return 'intermediate';
  }

  /**
   * æå–ä½¿ç”¨åœºæ™¯
   */
  static extractUseCases(text: string): string[] {
    const useCases = [];

    const patterns = {
      'å†™åšå®¢æ–‡ç« ': /(?:å†™|å†™|åˆ›ä½œ|ç”Ÿæˆ)(?:åšå®¢|æ–‡ç« |post|content)/gi,
      'ç”Ÿæˆä»£ç ': /(?:ç”Ÿæˆ|å†™|åˆ›å»º)(?:ä»£ç |ç¼–ç¨‹|code|programming|app|application)/gi,
      'æ’°å†™é‚®ä»¶': /(?:å†™|åˆ›å»º|ç”Ÿæˆ)(?:é‚®ä»¶|é‚®ä»¶|email|message)/gi,
      'è®¾è®¡å›¾å½¢': /(?:è®¾è®¡|åˆ›å»º|ç”Ÿæˆ)(?:å›¾å½¢|å›¾ç‰‡|UI|UX|design|graphic|image)/gi,
      'åˆ†ææ•°æ®': /(?:åˆ†æ|ç»Ÿè®¡|æŠ¥å‘Š|å¯è§†åŒ–)(?:æ•°æ®|åˆ†æ|analytics|data|visualize|report)/gi,
      'åˆ›å»ºè¥é”€å†…å®¹': /(?:ç”Ÿæˆ|å†™|åˆ›ä½œ)(?:è¥é”€|å¹¿å‘Š|å†…å®¹|æ–‡æ¡ˆ|copywriting|marketing|content)/gi,
      'ä¼˜åŒ–æ–‡æœ¬': /(?:ä¼˜åŒ–|æ”¹è¿›|ç¼–è¾‘)(?:æ–‡æœ¬|å†…å®¹|text|content|optimize|improve|edit)/gi,
      'ç”Ÿæˆåˆ›æ„': /(?:ç”Ÿæˆ|åˆ›å»º|æƒ³å‡º)(?:åˆ›æ„|æƒ³æ³•|idea|creative|ideation|brainstorm)/gi
    };

    for (const [useCase, pattern] of Object.entries(patterns)) {
      if (pattern.test(text)) {
        useCases.push(useCase);
      }
    }

    return useCases.slice(0, 5);
  }

  /**
   * æ£€æµ‹ä¸“ä¸šé¢†åŸŸ
   */
  static detectExpertise(text: string): string[] {
    const expertise = [];
    const patterns = {
      'è‡ªç„¶è¯­è¨€å¤„ç†': /(?:NLP|è‡ªç„¶è¯­è¨€|æ–‡æœ¬å¤„ç†|text processing|natural language)/gi,
      'è®¡ç®—æœºè§†è§‰': /(?:CV|è®¡ç®—æœºè§†è§‰|å›¾åƒè¯†åˆ«|image recognition|computer vision)/gi,
      'æœºå™¨å­¦ä¹ ': /(?:æœºå™¨å­¦ä¹ |ML|machine learning|algorithmic learning)/gi,
      'æ·±åº¦å­¦ä¹ ': /(?:æ·±åº¦å­¦ä¹ |DL|deep learning|neural|cnn|rnn)/gi,
      'å¤§è¯­è¨€æ¨¡å‹': /(?:LLM|å¤§æ¨¡å‹|large language model|GPT|Transformer|BERT)/gi
    };

    text = text.toLowerCase();

    for (const [exp, pattern] of Object.entries(patterns)) {
      if (pattern.test(text)) {
        expertise.push(exp);
      }
    }

    return expertise.slice(0, 3);
  }

  /**
   * æ‰¹é‡æŠ“å–
   */
  static async scrapeBatch(queries: string[]): Promise<any[]> {
    const results = await Promise.all(
      queries.map(query => this.scrapeTwitter(query, 20))
    );

    return results.flatMap(result => result.prompts);
  }

  /**
   * å®šæ—¶æŠ“å–
   */
  static async scheduleScrape(queries: string[], interval: number = 3600000): Promise<void> {
    console.log(`â°  Scheduled scrape every ${interval / 60000} hours`);

    while (true) {
      const startTime = Date.now();

      try {
        // æ‰¹é‡æŠ“å–
        const prompts = await this.scrapeBatch(queries);
        console.log(`âœ… Scraped ${prompts.length} prompts`);

        // è¯„ä¼°æ‰€æœ‰æç¤ºè¯
        const { EvaluationService } = await import('./evaluationService');
        const evaluated = await EvaluationService.evaluateBatch(prompts);
        const sorted = EvaluationService.sortAndRank(evaluated);

        // ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆæ¨¡æ‹Ÿï¼‰
        console.log(`âœ… Evaluated and sorted ${sorted.length} prompts`);

      } catch (error) {
        console.error('âŒ Error in scheduled scrape:', error);
      }

      // ç­‰å¾…ä¸‹ä¸€æ¬¡æŠ“å–
      const elapsedTime = Date.now() - startTime;
      const waitTime = Math.max(0, interval - elapsedTime);
      console.log(`â³  Waiting ${waitTime / 1000} seconds until next scrape...`);
      await new Promise(resolve => setTimeout(resolve, waitTime));
    }
  }
}
